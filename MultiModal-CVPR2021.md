## Multi-modal learning paper in CVPR2021

### Text-to-Image Generation
|No.  |Model Name |Title |Links |Pub. | Organization| 
|-----|:-----:|:-----:|:-----:|:--------:|:---:|
|0|XMC-GAN| Cross-Modal Contrastive Learning for Text-to-Image Generation | [paper](https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Cross-Modal_Contrastive_Learning_for_Text-to-Image_Generation_CVPR_2021_paper.html)| CVPR 2021 | Google Research|

### Autonomous Driving 
|No.  |Model Name |Title |Links |Pub. | Organization| 
|-----|:-----:|:-----:|:-----:|:--------:|:---:|
|0|MVDNet|Robust Multimodal Vehicle Detection in Foggy Weather Using Complementary Lidar and Radar Signals   |[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Qian_Robust_Multimodal_Vehicle_Detection_in_Foggy_Weather_Using_Complementary_Lidar_CVPR_2021_paper.pdf) [code](https://github.com/qiank10/MVDNet)| CVPR 2021 | University of California SanDiego |
|1|-| Multi-Modal Fusion Transformer for End-to-End Autonomous Driving | [paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Prakash_Multi-Modal_Fusion_Transformer_for_End-to-End_Autonomous_Driving_CVPR_2021_paper.pdf) | CVPR 2021 | Max Planck Institute for Intelligent Systems| 

### Navigation
|No.  |Model Name |Title |Links |Pub. | Organization| 
|-----|:-----:|:-----:|:-----:|:--------:|:---:|
|0|VLN|Robust Multimodal Vehicle Detection in Foggy Weather Using Complementary Lidar and Radar Signals   |[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Qian_Robust_Multimodal_Vehicle_Detection_in_Foggy_Weather_Using_Complementary_Lidar_CVPR_2021_paper.pdf) [code](https://github.com/qiank10/MVDNet)| CVPR 2021 | University of California SanDiego |
|1|SSM | Structured Scene Memory for Vision-Language Navigation| [paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Structured_Scene_Memory_for_Vision-Language_Navigation_CVPR_2021_paper.pdf) | CVPR 2021 | Beijing Institute of Technology |



### OCR
|No.  |Model Name |Title |Links |Pub. | Organization| 
|-----|:-----:|:-----:|:-----:|:--------:|:---:|
|0|-|Semantic-Aware Video Text Detection |[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Feng_Semantic-Aware_Video_Text_Detection_CVPR_2021_paper.pdf) | CVPR 2021 | National Laboratory of Pattern Recognition |
|1| TRBA | What If We Only Use Real Datasets for Scene Text Recognition?Toward Scene Text Recognition With Fewer Labels | [paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Baek_What_if_We_Only_Use_Real_Datasets_for_Scene_Text_CVPR_2021_paper.pdf) [code](https://github.com/ku21fan/STR-Fewer-Labels) | CVPR 2021 | The University of Tokyo|
|2| Multiplexed TextSpotter | A Multiplexed Network for End-to-End, Multilingual OCR| [paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_A_Multiplexed_Network_for_End-to-End_Multilingual_OCR_CVPR_2021_paper.pdf)| CVPR 2021 | Facebook AI|
|3|STKM | Self-attention based Text Knowledge Mining for Text Detection | [paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Wan_Self-Attention_Based_Text_Knowledge_Mining_for_Text_Detection_CVPR_2021_paper.pdf) | CVPR 2021 | Shenzhen University |

### Video Moment Retreival
|No.  |Model Name |Title |Links |Pub. | Organization| 
|-----|:-----:|:-----:|:-----:|:--------:|:---:|
|0|-| Multi-Modal Relational Graph for Cross-Modal Video Moment Retrieval|[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Zeng_Multi-Modal_Relational_Graph_for_Cross-Modal_Video_Moment_Retrieval_CVPR_2021_paper.pdf) | CVPR 2021 | Hunan University|

### video-audio-text 
|No.  |Model Name |Title |Links |Pub. | Organization| 
|-----|:-----:|:-----:|:-----:|:--------:|:---:|
|0|| How2Sign: A Large-scale Multimodal Datasetfor Continuous American Sign Language|[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Duarte_How2Sign_A_Large-Scale_Multimodal_Dataset_for_Continuous_American_Sign_Language_CVPR_2021_paper.pdf) [dataset](http://how2sign.github.io/) | CVPR 2021 | Universitat Polit\`ecnica de Catalunya|

### Image&Language
|No.  |Model Name |Title |Links |Pub. | Organization| 
|-----|:-----:|:-----:|:-----:|:--------:|:---:|
|0|| Image Change Captioning by Learning from an Auxiliary Task|[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Hosseinzadeh_Image_Change_Captioning_by_Learning_From_an_Auxiliary_Task_CVPR_2021_paper.pdf)  | CVPR 2021 |University of Manitoba|
|1| UC^2 | UC2: Universal Cross-lingual Cross-modal Vision-and-Language Pre-training |[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_UC2_Universal_Cross-Lingual_Cross-Modal_Vision-and-Language_Pre-Training_CVPR_2021_paper.pdf) | CVPR 2021 | University of California, Davis|
|2|-| How Transferable are Reasoning Patterns in VQA?|[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Kervadec_How_Transferable_Are_Reasoning_Patterns_in_VQA_CVPR_2021_paper.pdf)  [code](https://reasoningpatterns.github.io) | CVPR 2021 |INSA Lyon|
|3|M3p | M3P: Learning Universal Representations via Multitask MultilingualMultimodal Pre-training |  [paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Ni_M3P_Learning_Universal_Representations_via_Multitask_Multilingual_Multimodal_Pre-Training_CVPR_2021_paper.pdf) | CVPR 2021 | HiT |
|4| CC12M | Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts | [paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Changpinyo_Conceptual_12M_Pushing_Web-Scale_Image-Text_Pre-Training_To_Recognize_Long-Tail_Visual_CVPR_2021_paper.pdf)  | CVPR 2021 | Google Research|
|5| - | Separatin Skills and Concepts for Novel Visual Questions Answering| [paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Whitehead_Separating_Skills_and_Concepts_for_Novel_Visual_Question_Answering_CVPR_2021_paper.pdf) | CVPR 2021 |UIUC | 
|6| VinVL | VinVL: Revisiting Visual Representations in Vision-Language Models | [paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_VinVL_Revisiting_Visual_Representations_in_Vision-Language_Models_CVPR_2021_paper.pdf) [code](https://github.com/pzzhang/VinVL) | CVPR 2021 | Microsoft |
|7| -| Domain-robus VQA with diverse datasets and methods but no target labels | [paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Domain-Robust_VQA_With_Diverse_Datasets_and_Methods_but_No_Target_CVPR_2021_paper.pdf) | CVPR 2021 | University of Pittsburgh |
|8| PCME | Probabilistic Embeddings for Cross-Modal Retrieval | [paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Chun_Probabilistic_Embeddings_for_Cross-Modal_Retrieval_CVPR_2021_paper.pdf) [code](https://github.com/naver-ai/pcme) | CVPR 2021 | NAVER AI Lab|
|9| -| Thinking Fast and Slow: Efficient Text-to-Visual Retrieval with Transformers |[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Miech_Thinking_Fast_and_Slow_Efficient_Text-to-Visual_Retrieval_With_Transformers_CVPR_2021_paper.pdf)| CVPR 2021 | DeepMind|



### Video\&Text
|No.  |Model Name |Title |Links |Pub. | Organization| 
|-----|:-----:|:-----:|:-----:|:--------:|:---:|
|0| ClipBERT | Less Is More: ClipBERT for Video-and-Language Learning via Sparse Sampling  | [paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Lei_Less_Is_More_ClipBERT_for_Video-and-Language_Learning_via_Sparse_Sampling_CVPR_2021_paper.pdf) [code](https://github.com/jayleicn/ClipBERT) | CVPR 2021 | UNC|

### 3D cross-modal retreival
|No.  |Model Name |Title |Links |Pub. | Organization| 
|-----|:-----:|:-----:|:-----:|:--------:|:---:|
|0| -| Cross-Modal Center Loss for 3D Cross-Modal Retrieval | [paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Jing_Cross-Modal_Center_Loss_for_3D_Cross-Modal_Retrieval_CVPR_2021_paper.pdf) | CVPR 2021 | The City University of New York|


### Video-to-Text Generation
|No.  |Model Name |Title |Links |Pub. | Organization| 
|-----|:-----:|:-----:|:-----:|:--------:|:---:|
|0| Vx2Text |VX2TEXT: End-to-End Learning of Video-Based Text GenerationFrom Multimodal Inputs| [paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Lin_Vx2Text_End-to-End_Learning_of_Video-Based_Text_Generation_From_Multimodal_Inputs_CVPR_2021_paper.pdf) | CVPR 2021 | Columbia University |


### Image-to-Video Synthesis
|No.  |Model Name |Title |Links |Pub. | Organization| 
|-----|:-----:|:-----:|:-----:|:--------:|:---:|
|0|cINNs| Stochastic Image-to-Video Synthesis using cINNs|[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Dorkenwald_Stochastic_Image-to-Video_Synthesis_Using_cINNs_CVPR_2021_paper.pdf)  | CVPR 2021 |Heidelberg University|
|1| |Understanding Object Dynamics for Interactive Image-to-Video Synthesis|[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Blattmann_Understanding_Object_Dynamics_for_Interactive_Image-to-Video_Synthesis_CVPR_2021_paper.pdf) [code](https://bit.ly/3cxfA2L) | CVPR 2021 | Heidelberg University|


### Audo&Visual
|No.  |Model Name |Title |Links |Pub. | Organization| 
|-----|:-----:|:-----:|:-----:|:--------:|:---:|
|0|-| Can audio-visual integration strengthen robustnessunder multimodal attacks?|[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Tian_Can_Audio-Visual_Integration_Strengthen_Robustness_Under_Multimodal_Attacks_CVPR_2021_paper.pdf)  | CVPR 2021 |University of Rochester|

### Language-guided video actor segmentation
|No.  |Model Name |Title |Links |Pub. | Organization| 
|-----|:-----:|:-----:|:-----:|:--------:|:---:|
|0|-| Collaborative Spatial-Temporal Modeling for Language-QueriedVideo Actor Segmentation|[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Hui_Collaborative_Spatial-Temporal_Modeling_for_Language-Queried_Video_Actor_Segmentation_CVPR_2021_paper.pdf) | CVPR 2021 |Chinese Academy of Sciences|


