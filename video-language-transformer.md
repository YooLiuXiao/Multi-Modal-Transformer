# Video & Language Transformer

|No.  |Model Name |Title |Links |Pub. | Organization| Release Time |
|-----|:-----:|:-----:|:-----:|:--------:|:---:|:-------:|
|1|COOT |COOT: Cooperative Hierarchical Transformer for Video-Text Representation Learning |[paper](https://proceedings.neurips.cc/paper/2020/file/ff0abbcc0227c9124a804b084d161a2d-Paper.pdf) [code](https://github.com/gingsi/coot-videotext) |__Neurips 2020__|University of Freiburg|1 Nov 2020|
|2|MMT |Multi-modal Transformer for Video Retrieval |[paper](https://arxiv.org/abs/2007.10639) [code](https://github.com/gabeur/mmt) |__ECCV 2020__|Inria & Google|21 Jul 2020|
|3|HiT |HiT: Hierarchical Transformer with Momentum Contrast for Video-Text Retrieval |[paper](https://arxiv.org/abs/2103.15049) |__arXiv__|Peking University|28 Mar 2021|
|4|CLIPBERT |Less is More: CLIPBERT for Video-and-Language Learning via Sparse Sampling |[paper](https://arxiv.org/pdf/2102.06183.pdf) [code](https://github.com/jayleicn/ClipBERT) |__CVPR 2021__|UNC Chapel Hill|11 Feb 2020|
|5|SVRTN |Self-supervised Video Retrieval Transformer Network |[paper](https://arxiv.org/pdf/2104.07993.pdf) |__arXiv__|Alibaba DAMO Academy|16 Apr 2021|
|6| VATT| VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text | [paper](https://arxiv.org/pdf/2104.11178.pdf) | __arXiv__| Google | 22 April 2021|
|7|Forzen in Time | Forzen in Time: A Joint Video and Image Encoder for End-to-End Retrieval| [paper](https://arxiv.org/pdf/2104.00650.pdf) [code](https://github.com/m-bain/frozen-in-time) | __arXiv__ | University of Oxford| 1 April 2021|
|8|CLIP4CLIP| CLIP4Clip: An Empirical Study of CLIP for End to End Video Clip Retrieval | [paper](https://arxiv.org/pdf/2104.08860.pdf) [code](https://github.com/ArrowLuo/CLIP4Clip)  |   __arXiv__|  Southwest Jiaotong University | 18 April 2021 |
|9|CLIP2Video| CLIP2Video: Mastering Video-Text Retrieval via Image CLIP |  [paper](https://arxiv.org/pdf/2106.11097.pdf) [code](https://github.com/CryhanFang/CLIP2Video) | __arXiv__| PCG, Tencent | 21 June, 2021 |
|10| T2VLAD| T2VLAD: Global-Local Sequence Alignment for Text-Video Retrieval | [paper](https://arxiv.org/abs/2104.10054)  | CVPR 2021 | Baidu | 20 April 2021 | 
|11|-| On Semantic Similarity in Video Retrieval | [paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Wray_On_Semantic_Similarity_in_Video_Retrieval_CVPR_2021_paper.pdf)  [code](https://github.com/mwray/Semantic-Video-Retrieval) | CVPR 2021 |Univesity of Bristol | 21 June, 2021|
|12| VLM|VLM: Task-agnostic Video-Language Model Pre-training for Video Understanding| [paper](https://arxiv.org/pdf/2105.09996.pdf) | arXiv | Facebook AI | 20 May 2021|
|13| VideoBERT| VideoBERT: A Joint Model for Video and Language Representation Learning |[paper](https://arxiv.org/abs/1904.01766) | CVPR 2019 | Google Research | 11 Sep 2019 |
|14| CBT | learning video representations using contrastive bidirectional transformer |[paper](https://arxiv.org/pdf/1906.05743.pdf)| arXiv | Google Research |  27 Sep 2019|
|15 | ActBERT | ActBERT: Learning Global-Local Video-Text Representations |[paper](https://arxiv.org/abs/2011.07231) |  Baidu Research | CVPR 2020 | 14 Nov 2020| 
|16 | HERO |  HERO: Hierarchical Encoder for Video+Language Omni-representation Pre-training  |[paper](https://aclanthology.org/2020.emnlp-main.161.pdf) [code](https://github.com/linjieli222/HERO) | EMNLP 2020 | Microsoft Dynamics 365 AI Research | 29 Sep 2020 |
| 17 | UniVL | UniVL: A Unified Video and Language Pre-Training Model for Multimodal Understanding and Generation | [paper](https://arxiv.org/pdf/2002.06353.pdf) [code](https://github.com/microsoft/UniVL) |arXiv| MSRA| 15 Sep 2021|
  


# cross-domain video-retreival 
|No.  |Model Name |Title |Links |Pub. | Organization| Release Time |
|-----|:-----:|:-----:|:-----:|:--------:|:---:|:-------:|
|1| -| Adaptive Cross-Modal Prototypes for Cross-Domain Visual-Language Retrieval | [paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Adaptive_Cross-Modal_Prototypes_for_Cross-Domain_Visual-Language_Retrieval_CVPR_2021_paper.pdf) | CVPR 2021 | Zhejiang University| 20 April 2021| 


# vision & language navigation
|No.  |Model Name |Title |Links |Pub. | Organization| Release Time |
|-----|:-----:|:-----:|:-----:|:--------:|:---:|:-------:|
|1|Episodic Transformer | Episodic Transformer for Vision-and-Language Navigation| [paper](https://arxiv.org/pdf/2105.06453.pdf) | arXiv | Inria |  13 May 2021| 







