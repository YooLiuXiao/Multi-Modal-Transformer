# Video & Language Transformer

|No.  |Model Name |Title |Links |Pub. | Organization| Release Time |
|-----|:-----:|:-----:|:-----:|:--------:|:---:|:-------:|
|1|COOT |COOT: Cooperative Hierarchical Transformer for Video-Text Representation Learning |[paper](https://proceedings.neurips.cc/paper/2020/file/ff0abbcc0227c9124a804b084d161a2d-Paper.pdf) [code](https://github.com/gingsi/coot-videotext) |__Neurips 2020__|University of Freiburg|1 Nov 2020|
|2|MMT |Multi-modal Transformer for Video Retrieval |[paper](https://arxiv.org/abs/2007.10639) [code](https://github.com/gabeur/mmt) |__ECCV 2020__|Inria & Google|21 Jul 2020|
|3|HiT |HiT: Hierarchical Transformer with Momentum Contrast for Video-Text Retrieval |[paper](https://arxiv.org/abs/2103.15049) |__arXiv__|Peking University|28 Mar 2021|
|4|CLIPBERT |Less is More: CLIPBERT for Video-and-Language Learning via Sparse Sampling |[paper](https://arxiv.org/pdf/2102.06183.pdf) [code](https://github.com/jayleicn/ClipBERT) |__CVPR 2021__|UNC Chapel Hill|11 Feb 2020|
|5|SVRTN |Self-supervised Video Retrieval Transformer Network |[paper](https://arxiv.org/pdf/2104.07993.pdf) |__arXiv__|Alibaba DAMO Academy|16 Apr 2021|
|6| VATT| VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text | [paper](https://arxiv.org/pdf/2104.11178.pdf) | __arXiv__| Google | 22 April 2021|
|7|Forzen in Time | Forzen in Time: A Joint Video and Image Encoder for End-to-End Retrieval| [paper](https://arxiv.org/pdf/2104.00650.pdf) [code](https://github.com/m-bain/frozen-in-time) | __arXiv__ | University of Oxford| 1 April 2021|
|8|CLIP4CLIP| CLIP4Clip: An Empirical Study of CLIP for End to End Video Clip Retrieval | [paper](https://arxiv.org/pdf/2104.08860.pdf) [code](https://github.com/ArrowLuo/CLIP4Clip)  |   __arXiv__|  Southwest Jiaotong University | 18 April 2021 |









## Common Datasets
|No. |Dataset Name |Download Link|
|-----|:-----:|:-----:|

