# Video Transformer

|No.  |Model Name |Title |Links |Pub. | Organization| Release Time |
|-----|:-----:|:-----:|:-----:|:--------:|:---:|:-------:|
|1|TimeSformer |Is Space-Time Attention All You Need for Video Understanding? |[paper](https://arxiv.org/abs/2102.05095) [code](https://github.com/facebookresearch/TimeSformer) |__arXiv__|Facebook AI|24 Feb 2021|
|2|Video Transformer |Video Transformer Network |[paper](https://arxiv.org/abs/2102.00719) |__arXiv__|Theator|1 Feb 2021|
|3|ViViT |ViViT: A Video Vision Transformer |[paper](https://arxiv.org/pdf/2103.15691.pdf) |__arXiv__|Google AI|29 Mar 2021|
|4|VideoGPT |  VideoGPT: Video Generation using VQ-VAE and Transformers |  [paper](https://arxiv.org/pdf/2104.10157.pdf) [code](https://wilson1yan.github.io/videogpt/index.html)  | __arXiv__ | UC Berkeley | 20 Apr 2021|
|5|VIMPAC|VIMPAC: Video Pre-Training via Masked Token Prediction and Contrastive Learning| [paper](https://arxiv.org/pdf/2106.11250.pdf) [code](https://github.com/airsplay/vimpac) | __arXiv__ | UNC| 21 June 2021|
|6|-| Self-supervised Video Representation Learning by Context and Motion Decoupling | [paper](https://arxiv.org/pdf/2104.00862.pdf)| CVPR 2021 | Alibaba | 2 April 2021|
|7|VideoLightFormer| VideoLightFormer: Lightweight Action Recognition using Transformers| [paper](https://arxiv.org/pdf/2107.00451v1.pdf) | arXiv| the university of shefield| 1 Jul 2021|
|8|Video Swin Transformer| Video Swin Transformer| [paper](https://arxiv.org/pdf/2106.13230.pdf) [code](https://github.com/SwinTransformer/Video-Swin-Transformer) | arXiv | MSRA | 24 Jun 2021|
|9| ST Swin| Long-Short Temporal Contrastive Learning of Video Transformers| [paper](https://arxiv.org/pdf/2106.09212.pdf) |arXiv|Facebook AI|  17 Jun 2021|
|10|X-ViT|Space-time Mixing Attention for Video Transformer| [paper](https://arxiv.org/pdf/2106.05968.pdf) | arXiv|  Samsung AI Cambridge |11 Jun 2021| 
|11| OCVT | Generative Video Transformer: Can Objects be the Words? | [paper](https://arxiv.org/abs/2107.09240) | ICML 2021 |Rutgers University | 20 Jul 2021|
|12|-|An Image is Worth 16x16 Words, What is a Video Worth?| [paper](https://arxiv.org/pdf/2103.13915.pdf) [code](https://github.com/Alibaba-MIIL/STAM) | arXiv | Alibaba |27 May 2021|
|13| SCT| Shifted Chunk Transformer for Spatio-Temporal Representational Learning | [paper](https://arxiv.org/pdf/2108.11575.pdf) | arXiv | Kuaishou Technology | 26 Aug 2021|
|14| -| Evaluating Transformers for Lightweight Action Recognition | [paper](https://arxiv.org/pdf/2111.09641.pdf) | arXiv | University of Sheffield | 18 Nov 2021|
|15| DualFormer| DualFormer: Local-Global Stratified Transformer for Efficient Video Recognition | [paper](https://arxiv.org/pdf/2112.04674v1.pdf) | arXiv |Sea AI Lab | 9 Dec 2021|
|16| BEVT| BEVT: BERT Pretraining of Video Transformers | [paper](https://arxiv.org/pdf/2112.01529.pdf) | arXiv | Shanghai Key Lab of Intelligent Information Processing | 2 Dec 2021|
|17|-| Efficient Video Transformers with Spatial-Temporal Token Selection|[paper](https://arxiv.org/pdf/2111.11591.pdf)| arXiv | Shanghai Key Lab of Intelligent Information Processing | 23 Nov 2021|
|18| -| Lite Vision Transformer with Enhanced Self-Attention| [paper](https://arxiv.org/pdf/2112.10809.pdf) [code](https://github.com/Chenglin-Yang/LVT) | arXiv | Johns Hopkins University | 20 Dec 2021|
|19|MViT| Multiscale Vision Transformers| [paper](https://arxiv.org/pdf/2104.11227.pdf) [code](https://github.com/facebookresearch/SlowFast)| ICCV 2021 | Facebook| 22 Apr 2021|
|20| Uniformer| Uniformer: Unified Transformer For Efficient Spatiotemporal Representation Learning| [paper](https://openreview.net/pdf?id=nBU_u6DLvoK) [code](https://github.com/sense-x/uniformer) | arXiv | Chinese Academy of Sciences|12 Jan 2022|
|21|MaskFeat| Masked Feature Prediction for Self-Supervised Visual Pre-Training| [paper](https://arxiv.org/pdf/2112.09133v1.pdf)| arXiv | Facebook AI |16 Dec 2021|
|22|MTV| Multiview Transformers for Video Recognition| [paper](https://arxiv.org/pdf/2201.04288.pdf) |arXiv| Google | 20 Jan 2022|
