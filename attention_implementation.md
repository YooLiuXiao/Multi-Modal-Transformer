# This page collects different representative designs of attention module

[references](https://github.com/xmu-xiaoma666/External-Attention-pytorch)
