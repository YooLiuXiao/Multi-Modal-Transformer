# Compressed Transformer

|No.  |Model Name |Title |Links |Pub. | Organization| Release Time |
|-----|:-----:|:-----:|:-----:|:--------:|:---:|:-------:|
|1| VTP |Vision Transformer Pruning |[paper](https://arxiv.org/pdf/2104.08500.pdf) |__KDD 2021 workshop__|Westlake University|14 Aug 2021|
|2| IA-RED2 | IA-RED2 : Interpretability-Aware Redundancy Reduction for Vision Transformers | [paper](https://proceedings.neurips.cc/paper/2021/hash/d072677d210ac4c03ba046120f0802ec-Abstract.html) [code](http://people.csail.mit.edu/bpan/ia-red/) | __NeurIPS 2021__ | MIT| 23 Jun 2021|
|3| DynamicViT| DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification | [paper](https://arxiv.org/pdf/2106.02034.pdf) [code](https://github.com/raoyongming/DynamicViT) |  Tsinghua University| 26 Oct 2021|
|4|  Evo-ViT| Evo-ViT: Slow-Fast Token Evolution for Dynamic Vision Transformer| [paper](https://arxiv.org/pdf/2108.01390.pdf) [code](https://github.com/YifanXu74/Evo-ViT)| Chinese Academy of Sciences |6 Dec 2021|
|5| - |Patch Slimming for Efficient Vision Transformers| [paper](https://arxiv.org/pdf/2106.02852.pdf) | Peking University|5 Jun 2021|
|6|-| Chasing Sparsity in Vision Transformers: An End-to-End Exploration| [paper](https://arxiv.org/pdf/2106.04533.pdf) [code](https://github.com/VITA-Group/SViTE) | University of Texas at Austin| 22 Oct 2021|
|7|DeIT| Training data-efficient image transformers & distillation through attention | [paper](https://arxiv.org/pdf/2012.12877.pdf) | Facebook | 15 Jan 2021|
|8| -|Post-Training Quantization for Vision Transformer| [paper](https://arxiv.org/abs/2106.14156) | Peking University| 27 Jun 2021|
