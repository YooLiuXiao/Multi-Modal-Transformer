# this will collect many papers that relates to self-supervied learning in vision domains.


Self-supervised learning for Images
|No.  |Model Name |Title |Links |Pub. | Organization| Release Time |
|-----|:-----:|:-----:|:-----:|:--------:|:---:|:-------:|
|1|iGPT |	Generative Pretraining from Pixels |[paper](http://proceedings.mlr.press/v119/chen20s/chen20s.pdf) [code](https://github.com/openai/image-gpt) |__ICML 2021__|OpenAI|17 June 2020|
|2| MST | MST: Masked Self-Supervised Transformer for Visual Representation | [paper](https://arxiv.org/pdf/2106.05656.pdf) | __NeurIPS 2021__|Chinese Academy of Sciences| 10 June 2021|
|3|BEiT| BEiT: BERT Pre-Training of Image Transformers| [paper](https://arxiv.org/abs/2106.08254) [code](https://github.com/microsoft/unilm/tree/master/beit) | __ICLR 2022__|Microsoft Research| 15 June 2021|
|4| MAE | Masked Autoencoders Are Scalable Vision Learners| [paper](https://arxiv.org/pdf/2111.06377.pdf) [code](https://github.com/facebookresearch/mae)| CVPR 2022| Meta | 19 Dec 2021|
|5| iBoT | iBOT: Image BERT Pre-Training with Online Tokenizer| [paper](https://arxiv.org/pdf/2111.07832.pdf) [code](https://github.com/bytedance/ibot) | ICLR 2022 | ByteDance |15 Nov 2021| 
|6| SimMIM| SimMIM: A Simple Framework for Masked Image Modeling | [paper](https://arxiv.org/pdf/2111.09886.pdf) [code](https://github.com/microsoft/SimMIM) | arXiv| MSRA| 18 Nov 2021| 
|7| PeCo | 	PeCo: Perceptual Codebook for BERT Pre-training of Vision Transformers | [paper](https://arxiv.org/pdf/2111.12710.pdf) |arXiv|  Univeristy of Science and Technology of China | 24 Nov 2021|
|8| MaskFeat | 	Masked Feature Prediction for Self-Supervised Visual Pre-Training | [paper](https://arxiv.org/pdf/2112.09133.pdf) | arXiv | Meta | 16 Dec 2021|
|9| SplitMask | Are Large-scale Datasets Necessary for Self-Supervised Pre-training? | [paper](https://arxiv.org/pdf/2112.10740.pdf) | arXiv | Meta | 20 Dec 2021 | 
|10| ADIOS | Adversarial Masking for Self-Supervised Learning| [paper](https://arxiv.org/pdf/2201.13100.pdf) | ICML 2022 | Unviersity of Oxford | 31 Jan 2021|
|11| CAE | Context Autoencoder for Self-Supervised Representation Learning | [paper](https://arxiv.org/pdf/2202.03026.pdf) | arXiv | Peking University | 7 Feb 2022 |
|12| CIM| Corrupted Image Modeling for Self-Supervised Visual Pre-Training| [paper](https://arxiv.org/pdf/2202.03382.pdf) [code](https://github.com/microsoft/unilm) | arXiv | Microsoft | 7 Feb 2022|
|13| ConvMAE | ConvMAE: Masked Convolution Meets Masked Autoencoders |[paper](https://arxiv.org/pdf/2205.03892.pdf) [code](https://github.com/Alpha-VL/ConvMAE) | arXiv | Shanghai AI Laboratory |  19 May 2022 |



Self-supervised Learning for Videos
|No.  |Model Name |Title |Links |Pub. | Organization| Release Time |
|-----|:-----:|:-----:|:-----:|:--------:|:---:|:-------:|
|1| VideoMAE| VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training | [paper](https://arxiv.org/abs/2203.12602) [code](https://github.com/MCG-NJU/VideoMAE) | arXiv |  Tencent AI Lab | 23 Mar 2022 |
|2|MAE in Video| Masked Autoencoders As Spatiotemporal Learners | [paper](https://arxiv.org/pdf/2205.09113.pdf) | arXiv | Meta | 18 May 2022 |
