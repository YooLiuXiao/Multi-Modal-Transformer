# this will collect many papers that relates to self-supervied learning in vision domains.

|No.  |Model Name |Title |Links |Pub. | Organization| Release Time |
|-----|:-----:|:-----:|:-----:|:--------:|:---:|:-------:|
|1|iGPT |	Generative Pretraining from Pixels |[paper](http://proceedings.mlr.press/v119/chen20s/chen20s.pdf) [code](https://github.com/openai/image-gpt) |__ICML 2021__|OpenAI|17 June 2020|
|2| MST | MST: Masked Self-Supervised Transformer for Visual Representation | [paper](https://arxiv.org/pdf/2106.05656.pdf) | __NeurIPS 2021__|Chinese Academy of Sciences| 10 June 2021|
|3|BEiT| BEiT: BERT Pre-Training of Image Transformers| [paper](https://arxiv.org/abs/2106.08254) [code](https://github.com/microsoft/unilm/tree/master/beit) | __ICLR 2022__|Microsoft Research| 15 June 2021|
|4| MAE | Masked Autoencoders Are Scalable Vision Learners| [paper](https://arxiv.org/pdf/2111.06377.pdf) [code](https://github.com/facebookresearch/mae)| CVPR 2022| META | 19 Dec 2021|
