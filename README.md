# Reading list in Transformer

We are a team from KAUST [Vision-CAIR group](https://cemse.kaust.edu.sa/vision-cair) and focus on the Multi-modal representation learning. 

This repo is aimed to collect all the recent popular Transformer paper, codes and learning resources with respect to the domains of **Vision Transformer**, **NLP** and **multi-modal**, etc. 




### Topics (paper and code)
- [Image Transformer](image-transformer.md) 


- [Video Transformer](video-transformer.md)


- [Video & Language & other modality Transformer](video-language-transformer.md)


- [Image & language & other modlity Trasformer](image-language-transformer.md)


- [Natural Language Processing Transformer](NLP-transformer.md)


- [Efficient Transformer](efficiency-transformer.md)

- [model compression](vision_model_compression.md)

- [Self Supverpervised Learning in Vision](Self-supervised_learning_in_vision.md)

<!-- - [MLP for Image Classification](MLP-mixer.md) -->

- [other interested papers in related domains](other_interesting_paper.md)


Review Paper in multi-modal  
- [Video-language](paper-review.md)


### Tutorials and workshop
- [Cross-View and Cross-Modal Visual Geo-Localization: IEEE CVPR 2021 Tutorial](https://youtube.com/playlist?list=PLUgbVHjDharjTo9tk3xcPJHEkmi33ap-u)

- [From VQA to VLN: Recent Advances in Vision-and-Language Research: IEEE CVPR 2021 Tutorial](https://youtube.com/playlist?list=PLUgbVHjDhari645g1zmpo-MtOVap1FKxh)





### Datasets
- [Multi-modal Datasets](datasets.md)


### Blogs
- [Lil's blogs](https://lilianweng.github.io/lil-log/)

### Tools
- [PyTorchVideo](https://pytorchvideo.org/) a deep learning library for video understanding research

- [horovod](https://github.com/horovod/horovod) a tool for multi-gpu parallel processing

- [accelerate](https://huggingface.co/docs/accelerate/) an easy API for mixed precision and any kind of distributed computing

- [hyperparameter search: optuna](https://optuna.org/)

- [AI Conference Deadlines](https://aideadlin.es/)

