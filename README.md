# Reading list in Transformer

We are a team from KAUST [Vision-CAIR group](https://cemse.kaust.edu.sa/vision-cair) and focus on the Vision Transformer and Multi-modal learning. 

This repo is to collect all the recent popular Transformer paper and code related to the domains of **Vision Transformer**, **NLP** and **multi-modal**, etc.  
It also collects the related learning materials.


### Recent News

> The code and paper of Twins-SVT is open sourced. The apper and code can be found [here](image-transformer.md)	

> Vision Transformer for deepfake detection. The paper can be found [here](image-transformer.md)

> The code of VideoGPT is open sourced. The paper and code can be found [here](video-transformer.md)

> The code of CoaT is open sourced. The paper and code can be found [here](image-transformer.md)

> The code of Kaleido-BERT is open sourced. The paper and coda can be found [here](image-language-transformer.md)
 
 > The code of TimeSformer is open sourced.  The paper and code can be found [here](video-transformer.md)

 > The code of SwinTransformer is open sourced. The paper and code can be found [here](image-transformer.md) 
 
 > The code of VisualGPT is open sourced. The paper and code can be found [here](image-language-transformer.md)
 

 





### Topics (paper and code)
#### [Image Transformer](image-transformer.md) 


#### [Video Transformer](video-transformer.md)


#### [Video & Language & other modality Transformer](video-language-transformer.md)


#### [Image & language & other modlity Trasformer](image-language-transformer.md)


#### [Natural Language Processing Transformer](NLP-transformer.md)


#### [Efficient Transformer](efficiency-transformer.md)


### Tutorials




### Tools
[PyTorchVideo](https://pytorchvideo.org/) a deep learning library for video understanding research

[horovod](https://github.com/horovod/horovod) a tool for multi-gpu parallel processing

[accelerate](https://huggingface.co/docs/accelerate/) an easy API for mixed precision and any kind of distributed computing


